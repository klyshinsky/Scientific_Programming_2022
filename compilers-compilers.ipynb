{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ddadc6",
   "metadata": {},
   "source": [
    "## Инструменты для анализа контекстно-свободных грамматик\n",
    "\n",
    "#### Клышинский Э.С.\n",
    "#### 21.05.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105536b",
   "metadata": {},
   "source": [
    "Общая идея компиляторов компиляторов заключется в следующем. Обычный компилятор берет текст программы и переводит его, например, в машинный код. Компилатор компиляторов берет грамматику языка и перевод его в исходный код компилятора или интерпретатора данного языка, или в программу, которая просто проверяет правильность выражения.\n",
    "\n",
    "## LARK\n",
    "\n",
    "Для начала познакомимся с простой библиотекой Lark, имеющей ограниченный функционал. Класс из этой библиотеки принимает на вход грамматику в некотором формате. Далее она получает на вход строку и проверяет ее на соответствие этой грамматике.\n",
    "\n",
    "Хороший обзор разных библиотек находится [здесь](https://tomassetti.me/parsing-in-python/).\n",
    "\n",
    "К плюсам Lark относится [наличие](https://www.lark-parser.org/ide/) отладчика."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d112a8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lark in /home/edward/.local/lib/python3.10/site-packages (1.1.9)\n"
     ]
    }
   ],
   "source": [
    "# Установим библиотеку.\n",
    "!pip3 install lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c0f50",
   "metadata": {},
   "source": [
    "Пример, на котором мы будем разбирать работу библиотеки взят [отсюда](http://blog.erezsh.com/how-to-write-a-dsl-in-python-with-lark/) (но он также есть и в [документации](https://lark-parser.readthedocs.io/en/latest/examples/turtle_dsl.html)). Для него нам потребуется библиотека рисования `turtle`, которая требует установленного `tkInter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb9aea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] пароль для edward: \n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install python3-tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a4e34",
   "metadata": {},
   "source": [
    "Существует два принципиально разных подхода к написанию компиляторов компиляторов. Подход постарше заключается в написании грамматики, подход помладше состоит в написании кода на нужном вам языке программирования, который будет использоваться библиотекой для разбора. Мы с вами пройдем по классике.\n",
    "\n",
    "Так исторически сложилось, что грамматики для разных инструментов пишутся в примерно одинаковой нотации, различающейся особенностями работы. Выделяют описания лексем (единиц языка) и описания правил (в терминах БНФ). Для обоих видов сперва идет название, потом двоеточие, и после него - описание. Традиционно, названия лексем пишутся большими буквами, названия правил начинаются с маленькой буквы. Например,  \n",
    "`COLOR: (\"a\"..\"z\")+`  \n",
    "описывает лексему `COLOR`, описывающуюся при помощи регулярного выражения `(\"a\"..\"z\")+`. Правило  \n",
    "`code_block: \"{\" instruction+ \"}\"`  \n",
    "описывает правило `code_block`, состоящее из положительной итерации строк, описываемых правилом `instruction`, обрамленных фигурными скобками.\n",
    "Обратите внимание, что регулярные выражения библиотеки Lark имеют собственную нотацию.\n",
    "\n",
    "Положим грамматику в переменную, чтобы потом передать библиотеке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f346a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle_grammar = '''start: instruction+\n",
    " \n",
    "instruction: (\"f\"|\"b\"|\"l\"|\"r\") NUMBER\n",
    "           | \"c\" COLOR [COLOR]\n",
    "           | \"fill\" code_block\n",
    "           | \"repeat\" NUMBER code_block\n",
    " \n",
    "code_block: \"{\" instruction+ \"}\"\n",
    " \n",
    "COLOR: (\"a\"..\"z\")+\n",
    "NUMBER: (\"0\"..\"9\")+\n",
    "WHITESPACE: (\" \" | \"\\\\n\")+\n",
    "%ignore WHITESPACE\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f15c4",
   "metadata": {},
   "source": [
    "Напишем программу, которую мы собираемся выполнять при помощи библиотеки Lark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c04423",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "c red yellow\n",
    "fill { repeat 36 {\n",
    "    f200 l170\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca9409",
   "metadata": {},
   "source": [
    "Импортируем саму библиотеку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ac8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lark import Lark\n",
    "import lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa8579b",
   "metadata": {},
   "source": [
    "Создадим объект для разбора программ на нашем языке и передадим в него грамматику языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe92c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = Lark(turtle_grammar)  # Scannerless Earley is the default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9189a",
   "metadata": {},
   "source": [
    "Посмотрим что возвращает функция разбора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbebb11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree(Token('RULE', 'start'), [Tree(Token('RULE', 'instruction'), [Token('COLOR', 'red'), Token('COLOR', 'yellow')]), Tree(Token('RULE', 'instruction'), [Tree(Token('RULE', 'code_block'), [Tree(Token('RULE', 'instruction'), [Token('NUMBER', '36'), Tree(Token('RULE', 'code_block'), [Tree(Token('RULE', 'instruction'), [Token('NUMBER', '200')]), Tree(Token('RULE', 'instruction'), [Token('NUMBER', '170')])])])])])])\n"
     ]
    }
   ],
   "source": [
    "t = parser.parse(text)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ba8977",
   "metadata": {},
   "source": [
    "Ниже дается прямая и обратная польская запись выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "5-3-1\n",
    "-(-(5, 3), 1)\n",
    "((5,3)-, 1)-\n",
    "(1)\n",
    "\n",
    "((5,3)pow, (42, 12)-)-\n",
    "[95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecc09e",
   "metadata": {},
   "source": [
    "Ниже нарисована пара абстрактных синтаксических деревьев для вычисления арифметических выражений и для генератора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "5 - 3 - 1\n",
    "\n",
    "     -\n",
    "  -     1\n",
    "5  3\n",
    "\n",
    "1 - (5 - 3)\n",
    "     -\n",
    "  1     -    \n",
    "       5  3\n",
    "\n",
    "\n",
    "[f(i) for i in range(10, 20, 2)]\n",
    "\n",
    "      [for]\n",
    "   /    |      \\\n",
    "  i  range     f()\n",
    "    /  | \\     |\n",
    "    10 20 2    i\n",
    "\n",
    "    for\n",
    "  /  |  \\\n",
    "i   f2   f\n",
    "     |   |\n",
    "     +   i\n",
    "    / \\       \n",
    "   j   3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a2c00",
   "metadata": {},
   "source": [
    "Судя по нотации, она возвращает дерево, и это дерево разбора программы. Это же дерево можно нарисовать покрасивее средствами самой библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d45320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "  instruction\n",
      "    red\n",
      "    yellow\n",
      "  instruction\n",
      "    code_block\n",
      "      instruction\n",
      "        36\n",
      "        code_block\n",
      "          instruction\t200\n",
      "          instruction\t170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parser.parse(text).pretty())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ee89a",
   "metadata": {},
   "source": [
    "А можно нарисовать еще красивее при помощи вот [этой](https://github.com/klyshinsky/ipytreewidget) библиотечки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e7cb52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var timer;\n",
       "    \n",
       "function showHideTree(ide, prefix, ida){\n",
       "    if(document.getElementById(ida).innerHTML==\"▼\") {\n",
       "      document.getElementById(ide).style.display=prefix+\"block\";\n",
       "      document.getElementById(ida).innerHTML=\"▲\";}\n",
       "    else if(document.getElementById(ida).innerHTML==\"▲\") {\n",
       "      document.getElementById(ide).style.display=\"none\";\n",
       "      document.getElementById(ida).innerHTML=\"▼\";}\n",
       "     \n",
       "    if(document.getElementById(ida).innerHTML==\"►\") {\n",
       "      document.getElementById(ide).style.display=\"inline-block\";\n",
       "      document.getElementById(ida).innerHTML=\"◄\";}\n",
       "    else if(document.getElementById(ida).innerHTML==\"◄\") {\n",
       "      document.getElementById(ide).style.display=\"none\";\n",
       "      document.getElementById(ida).innerHTML=\"►\";}\n",
       "}\n",
       "\n",
       "function expandTree(element, display, prefix){\n",
       "  if( element.id.substr(0,4)==\"tlim\" ) {\n",
       "    var s = element.id.substr(0,3)+'a'+element.id.substr(4,20)\n",
       "    showHideTree(element.id, prefix, s);\n",
       "  }\n",
       "  \n",
       "  for(var i=0; i<element.children.length; i++) {\n",
       "    if(element.children[i].id[3]=='m' || element.children[i].id[3]=='a'|| element.children[i].id==\"\")\n",
       "      expandTree(element.children[i], display, prefix);\n",
       "  }  \n",
       "}\n",
       "\n",
       "function doubleClickTree(ide, prefix, ida){\n",
       "  if (timer) clearTimeout(timer);\n",
       "  \n",
       "  if(document.getElementById(ida).innerHTML==\"▼\") \n",
       "    expandTree(document.getElementById(ide), prefix+\"block\", prefix)\n",
       "  else if(document.getElementById(ida).innerHTML==\"▲\")\n",
       "    expandTree(document.getElementById(ide), \"none\", \"\")\n",
       "}\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipytreewidget import TreeWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8728ed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2933207359ed42208d5d3f4cbb768288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<div style=\"border: 1px solid #DDDDDD\"><div style=\"width:100%;background-color:#DDDDDD;padding-lef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def shape_lark_tree(tree):\n",
    "    '''Функция формирует дерево разбора в виде, понятном библиотеке отрисовки дерева.'''\n",
    "    if type(tree) is lark.lexer.Token:\n",
    "        dct = {\"text\": tree.type + ': ' + tree.title(), \"text-color\":\"#A64500\"}\n",
    "    elif type(tree) is lark.tree.Tree:\n",
    "        dct = {\"text\": str(tree.data), \"text-color\":\"#188A69\"}\n",
    "        childs = []\n",
    "        for child in tree.children:\n",
    "            childs.append(shape_lark_tree(child))\n",
    "        if childs != []:\n",
    "            dct[\"childs\"] = childs\n",
    "    return dct\n",
    "\n",
    "tree = parser.parse(text)\n",
    "tr2 = TreeWidget()\n",
    "tr2.show(shape_lark_tree(tree), \"<b>Parse Tree</b>\", footer=\"End of Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432bae92",
   "metadata": {},
   "source": [
    "Усложним грамматику, и вместо того, чтобы самим определять базовые лексемы, импортируем их из библиотеки.  \n",
    "Помимо этого, дадим уникальное имя для каждой продукции, чтбы различать какое из нескольких действий было совершено. Это сделает дерево разбора более читаемым: по нему будет понятно, что именно надо сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcb09469",
   "metadata": {},
   "outputs": [],
   "source": [
    "turtle_grammar = '''\n",
    "start: instruction+\n",
    " \n",
    "instruction: MOVEMENT NUMBER            -> movement\n",
    "           | \"c\" COLOR [COLOR]          -> change_color\n",
    "           | \"fill\" code_block          -> fill\n",
    "           | \"repeat\" NUMBER code_block -> repeat\n",
    " \n",
    "code_block: \"{\" instruction+ \"}\"\n",
    " \n",
    "MOVEMENT: \"f\"|\"b\"|\"l\"|\"r\"\n",
    "COLOR: LETTER+\n",
    " \n",
    "%import common.LETTER\n",
    "%import common.INT -> NUMBER\n",
    "%import common.WS\n",
    "%ignore WS\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0cb954a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25e380711ab4d809c1021cba961708a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<div style=\"border: 1px solid #DDDDDD\"><div style=\"width:100%;background-color:#DDDDDD;padding-lef…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = Lark(turtle_grammar)\n",
    "tree = parser.parse(text)\n",
    "tr2 = TreeWidget()\n",
    "tr2.show(shape_lark_tree(tree), \"<b>Parse Tree</b>\", footer=\"End of Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67043d68",
   "metadata": {},
   "source": [
    "Импортируем библиотеку `turtle` и выполним получившееся дерево.\n",
    "\n",
    "Вместо того, чтобы писать собственную функцию можно использовать [шаблон \"Слушатель\"](https://lark-parser.readthedocs.io/en/latest/visitors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a1b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d300212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_instruction(t):\n",
    "    if t.data == 'change_color':\n",
    "        turtle.color(*t.children)   # We just pass the color names as-is\n",
    " \n",
    "    elif t.data == 'movement':\n",
    "        name, number = t.children\n",
    "        {\n",
    "            'f': turtle.fd,\n",
    "            'b': turtle.bk,\n",
    "            'l': turtle.lt,\n",
    "            'r': turtle.rt,\n",
    "        }[name](int(number))\n",
    " \n",
    "    elif t.data == 'repeat':\n",
    "        count, block = t.children\n",
    "        for i in range(int(count)):\n",
    "            run_instruction(block)\n",
    " \n",
    "    elif t.data == 'fill':\n",
    "        turtle.begin_fill()\n",
    "        run_instruction(t.children[0])\n",
    "        turtle.end_fill()\n",
    " \n",
    "    elif t.data == 'code_block':\n",
    "        for cmd in t.children:\n",
    "            run_instruction(cmd)\n",
    " \n",
    "    else:\n",
    "        raise SyntaxError('Unknown instruction: %s' % t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963e3fd9",
   "metadata": {},
   "outputs": [
    {
     "ename": "Terminator",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTerminator\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_131132/172996996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_131132/2834379394.py\u001b[0m in \u001b[0;36mrun_instruction\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mturtle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrun_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mturtle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_131132/2834379394.py\u001b[0m in \u001b[0;36mrun_instruction\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'code_block'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mrun_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_131132/2834379394.py\u001b[0m in \u001b[0;36mrun_instruction\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mrun_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_131132/2834379394.py\u001b[0m in \u001b[0;36mrun_instruction\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'code_block'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mrun_instruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_131132/2834379394.py\u001b[0m in \u001b[0;36mrun_instruction\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'movement'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         {\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0;34m'f'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mturtle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m'b'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mturtle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36mlt\u001b[0;34m(angle)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36mleft\u001b[0;34m(self, angle)\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;36m67.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m         \"\"\"\n\u001b[0;32m-> 1699\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36m_rotate\u001b[0;34m(self, angle)\u001b[0m\n\u001b[1;32m   3275\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3277\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneworient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2660\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2661\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drawturtle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# TurtleScreenBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36m_update_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_incrementudc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updatecounter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/turtle.py\u001b[0m in \u001b[0;36m_incrementudc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTurtleScreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RUNNING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0mTurtleScreen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RUNNING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTerminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracing\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updatecounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTerminator\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for inst in tree.children:\n",
    "    run_instruction(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932f230",
   "metadata": {},
   "source": [
    "Вот [здесь](https://github.com/lark-parser/lark/tree/master/examples) есть еще немного примеров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d915aba",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4dc9d",
   "metadata": {},
   "source": [
    "## ANTLR\n",
    "\n",
    "Теперь посмотрим на другую библиотеку, устроенную несколько иначе - ANTLR.  \n",
    "Для этой библиотеки проще отдельно оформить файл с грамматикой. Сама грамматику устроена более сложно и в нее можно добавлять фрагменты собственного кода, которые будут вызываться по ходу разбора. Используя утилиту из командной строки, мы генерируем исходный код программы (в нашем случае на Питоне). Далее этот исходный код можно импортировать в свою собственную программу и инициировать разбор нужной нам строки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b388950",
   "metadata": {},
   "source": [
    "Инсталлируем всё необходимое программное обеспечение [отсюда](https://github.com/antlr/antlr4/blob/master/doc/getting-started.md) (или [отсюда](https://faun.pub/introduction-to-antlr-python-af8a3c603d23), если у вас Линукс хотя разница в инструкциях на одну Java) (или просто скачиваем [отсюда](https://www.antlr.org/download). Эти ссылки можно использовать и как введение самого начального уровня. Полная документация находится [здесь](https://github.com/antlr/antlr4/blob/4.6/doc/index.md). Хорошее и полное введение [здесь](https://tomassetti.me/antlr-mega-tutorial/).\n",
    "\n",
    "\n",
    "    cd /usr/local/lib\n",
    "    curl -O https://www.antlr.org/download/antlr-4.13.1-complete.jar\n",
    "    export CLASSPATH=”.:/usr/local/lib/antlr-4.5-complete.jar:$CLASSPATH” \n",
    "    # (Exports class path. Include in .bashrc file)\n",
    "    alias antlr4=’java -Xmx500M -cp “/usr/local/lib/antlr-4.5-complete.jar:$CLASSPATH” org.antlr.v4.Tool’ \n",
    "    # (Creates alias for ANTLR tool. Include in .bashrc file)\n",
    "    alias grun=’java org.antlr.v4.gui.TestRig’ \n",
    "    # (Creates alias for TestRig. Include in .bashrc file)\n",
    "    # Restart the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10fa2d28-cfac-4c33-b30d-2d2d628ee7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting antlr4-python3-runtime\n",
      "  Downloading antlr4_python3_runtime-4.12.0-py3-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: antlr4-python3-runtime\n",
      "Successfully installed antlr4-python3-runtime-4.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install antlr4-python3-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be95d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки.\n",
    "import sys\n",
    "from antlr4 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15ad6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переходим в каталог с грамматиками и запускаем утилиту, написанную на Java, для генерации исходного кода.\n",
    "!cd antlr_grammars && \\\n",
    "java -Xmx500M -cp \"/usr/local/lib/antlr-4.13.1-complete.jar\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T.g4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef9ca6",
   "metadata": {},
   "source": [
    "Посмотрим на параметры запуска утилиты.  \n",
    "`java -Xmx500M -cp \"/usr/local/lib/antlr-4.10.1-complete.jar\" org.antlr.v4.Tool`  \n",
    "Это мы запускаем программу на Java.  \n",
    "`-Dlanguage=Python3` - это мы просим ее компилировать выход для языка Питон.  \n",
    "`-o outputs` - это мы просим ее складывать все сгенерированные файлы в каталог `outputs`.  <br>\n",
    "`T.g4` - это мы просим ее сгенерировать код для грамматики из файла `T.g4`.\n",
    "\n",
    "Теперь посмотрим что нам сгенерировала утилита в каталоге `outputs`. Среди прочих файлов, в которых содержатся символы грамматики, обратим внимание на следующие.\n",
    "`TLexer.py` - файл с исходными кодами для лексического анализатора.  \n",
    "`TParser.py` - файл с исходными кодами для синтаксического анализатора.  \n",
    "`TListener.py` - файл с базовым классом, который обеспечивает обход дерева разбора.\n",
    "\n",
    "Постфикс в имени файлов стандартный, префикс совпадает с именем файла, содержащего грамматику.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3593d",
   "metadata": {},
   "source": [
    "Посмотрим на простую грамматику, разбирающую арифметические выражения в return. **Название грамматики в первой строке обязано совпадать с именем файла!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8750a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar T;\n",
      "\n",
      "stat: 'return ' e ';' # Return\n",
      " \t| 'break' ';' # Break\n",
      " \t;\n",
      "e   : e '*' e # Mult\n",
      "    | e '+' e # Add\n",
      "    | INT # Int\n",
      "    | ID # Id\n",
      "    ;\n",
      "\n",
      "WS : [ \\r\\t\\n]+ ;\n",
      "INT: [0-9]+;\n",
      "ID: [a-zA-Z][a-zA-Z0-9]*;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!more antlr_grammars/T.g4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed35ba59",
   "metadata": {},
   "source": [
    "Лексемы описываются при помощи обычных регулярных выражений. После решетки пишется название для конкретной продукции. ANTLR использует ее для того чтобы генерировать названия функций в классе Listener. На этом уровне синтаксис правил практически не отличается от того, что мы видеи у Lark.\n",
    "\n",
    "Файлы созданы, можно импортировать из них необходимые классы. Но так как Питон считает, что импортировать достаточно только один раз, будем сперва выгружать старые версии библиотек, а потом загружать их новую версию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c80da8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'antlr_grammars.outputs.TLexer' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.TLexer']\n",
    "    del sys.modules['antlr_grammars.outputs.TParser']\n",
    "    del sys.modules['antlr_grammars.outputs.TListener']\n",
    "from antlr_grammars.outputs.TLexer import TLexer\n",
    "from antlr_grammars.outputs.TParser import TParser\n",
    "from antlr_grammars.outputs.TListener import TListener"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160baa75",
   "metadata": {},
   "source": [
    "Создаем входной поток в зависимости от того, откуда мы хотим получить входную последовательность (`FileStream` для файла или `InputStream` для строки). Создаем объект для лексического анализа, отдаем его потоку для токенов. Создаем класс для синтаксического анализа `TParser`. Для него вызываем функцию с тем же именем, что и имя начального символа нашей грамматики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f79b528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = FileStream('antlr_grammars/T_in.txt')\n",
    "infile = InputStream(' return 1*2+asdf;')\n",
    "infile.consume()\n",
    "lexer = TLexer(infile)\n",
    "stream = CommonTokenStream(lexer)\n",
    "parser = TParser(stream)\n",
    "tree = parser.stat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1764cd46",
   "metadata": {},
   "source": [
    "Теперь переопределим некоторые функции у класса TListener с тем, чтобы они делали нужные нам действия: вывод абстрактного синтаксического дерева для заданного выражения.\n",
    "\n",
    "Сравнение \"Слушателя\" с \"Посетителем\" [здесь](https://habr.com/ru/post/259691/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78352c8-8f83-4577-b218-2f205beda576",
   "metadata": {},
   "outputs": [],
   "source": [
    "-\n",
    "  -\n",
    "    5\n",
    "    3\n",
    "  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5afb734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(TListener):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.shift = ''\n",
    "        self.shiftSize = 2\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Add.\n",
    "    def enterAdd(self, ctx:TParser.AddContext):\n",
    "        print(self.shift + '+')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Add.\n",
    "    def exitAdd(self, ctx:TParser.AddContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Mult.\n",
    "    def enterMult(self, ctx:TParser.MultContext):\n",
    "        print(self.shift + '*')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Mult.\n",
    "    def exitMult(self, ctx:TParser.MultContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Id.\n",
    "    def enterId(self, ctx:TParser.IdContext):\n",
    "        print(self.shift + ctx.getText())\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Int.\n",
    "    def enterInt(self, ctx:TParser.IntContext):\n",
    "        print(self.shift+ctx.getText())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4914968",
   "metadata": {},
   "source": [
    "Класс `ParseTreeWalker` позволяет \"гулять\" по дереву разбора и выполнять нужные действия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f1da26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+\n",
      "  *\n",
      "    1\n",
      "    2\n",
      "  asdf\n"
     ]
    }
   ],
   "source": [
    "printer = MyListener()\n",
    "walker = ParseTreeWalker()\n",
    "walker.walk(printer, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fed19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "104dc052",
   "metadata": {},
   "source": [
    "Изменим нашу грамматику, добавив в нее массу новых возможностей.\n",
    "\n",
    "Ключ `@header` позволяет добавить код, который будет помещен в начало файла с исходным кодом класса синтаксического анализатора.\n",
    "\n",
    "Ключ `@members` добавит члены в класс синтаксического анализатора. Теперь мы можем пользоваться нужными нам библиотеками и членами класса анализатора в ходе разбора.\n",
    "\n",
    "В фигурных скобках можно добавить исходный код, который будет выполняться сразу как только анализатор разберет правило до него. В ключе `@after` можно добавить код, который выполнится в случае успешного разбора цепочки при помощи правила. В добавляемом исходном коде можно исползовать свойства текущего правила или токена, добавив к нему в начале символ доллара. \n",
    "\n",
    "Секция `locals` после имени файла позволяет завести локальные переменные, к которым можно обращаться в коде, размещенном в вызываемых правилах. При повторном (например, рекурсивном) посещении этого правила переменные будут создаваться повторно.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bfbedaf-f52e-46f9-a603-50697cc24117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar T2;\n",
      "\n",
      "@header {\n",
      "import math\n",
      "}\n",
      " \n",
      "@members {\n",
      "res = \"\"\n",
      "}\n",
      "\n",
      "// Rule stat.\n",
      "stat locals [stack=[]]    :\n",
      "          'return ' e ';' \n",
      "          {print(\"calculated:\", $stack)} # Return\n",
      " \t| 'break' ';' # Break\n",
      " \t;\n",
      "\n",
      "// Rule e.\n",
      "e   \n",
      "@after{print(\"processed: \", $stat::stack);}\n",
      "    : e '*' e \n",
      "      {$stat::stack[-2]*=$stat::stack[-1]; $stat::stack.pop(); print(\"* \", end=''); \n",
      "      } # Mult\n",
      "    | e '+' e \n",
      "      {$stat::stack[-2]+=$stat::stack[-1]; $stat::stack.pop(); print(\"+ \", end=''); \n",
      "      } # Add\n",
      "    | 'pow(' INT {a=int($INT.text)} ',' INT {b=int($INT.text)} ')'\n",
      "      {\n",
      "$stat::stack.append(math.pow(a,b)); print(\"pow \", end=''); \n",
      "      } # Pow\n",
      "    | INT \n",
      "      {\n",
      "self.res+=$text; \n",
      "$stat::stack.append(int($text)); \n",
      "print(\"->\", $stat::stack)\n",
      "      } # Int\n",
      "    | ID # Id\n",
      "    ;\n",
      "\n",
      "// Lexer rules after.\n",
      "INT: [0-9]+;\n",
      "ID: [a-zA-Z][a-zA-Z0-9]*;\n",
      "WS : [ \\r\\t\\n]+ -> skip;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat antlr_grammars/T2.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76afcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd antlr_grammars && java -Xmx500M -cp \"/usr/local/lib/antlr-4.10.1-complete.jar:$CLASSPATH\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T2.g4\n",
    "!cd antlr_grammars && \\\n",
    "java -Xmx500M -cp \"/usr/local/lib/antlr-4.13.1-complete.jar\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T2.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0afa6654",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'antlr_grammars.outputs.T2Lexer' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T2Lexer']\n",
    "if 'antlr_grammars.outputs.T2Parser' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T2Parser']\n",
    "from antlr_grammars.outputs.T2Lexer import T2Lexer\n",
    "from antlr_grammars.outputs.T2Parser import T2Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01d88393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [10]\n",
      "-> [10, 2]\n",
      "processed:  [10, 2]\n",
      "* pow -> [20, 81.0, 2]\n",
      "processed:  [20, 81.0, 2]\n",
      "* processed:  [20, 162.0]\n",
      "+ processed:  [182.0]\n",
      "calculated: [182.0]\n"
     ]
    }
   ],
   "source": [
    "infile = InputStream(' return 10 * 2 + pow(3, 4) * 2;')\n",
    "infile.consume()\n",
    "lexer2 = T2Lexer(infile)\n",
    "stream = CommonTokenStream(lexer2)\n",
    "parser2 = T2Parser(stream)\n",
    "tree = parser2.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feef67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1022'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser2.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d6c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dfd76ef",
   "metadata": {},
   "source": [
    "Важен порядок следования операций в правиле!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e720f672-77e1-4d29-8617-4c159e3287c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar T3_incorrect;\n",
      "\n",
      "@header {\n",
      "import math\n",
      "}\n",
      " \n",
      "@members {\n",
      "res = \"\"\n",
      "}\n",
      "\n",
      "// Rule stat.\n",
      "stat locals [stack=[]]    :\n",
      "          'return ' e ';' \n",
      "          {print(\"calculated:\", $stack)} # Return\n",
      " \t| 'break' ';' # Break\n",
      " \t;\n",
      "\n",
      "// Rule e.\n",
      "e   \n",
      "@after{print(\"processed\", $stat::stack);}\n",
      "    : e '*' e \n",
      "      {$stat::stack[-2]*=$stat::stack[-1]; $stat::stack.pop(); print(\"*\"); \n",
      "      } # Mult\n",
      "    | e '/' e \n",
      "      {$stat::stack[-2]/=$stat::stack[-1]; $stat::stack.pop(); print(\"/\"); \n",
      "      } # Div\n",
      "    | e '+' e \n",
      "      {$stat::stack[-2]+=$stat::stack[-1]; $stat::stack.pop(); print(\"+\"); \n",
      "      } # Add\n",
      "    | e '-' e \n",
      "      {$stat::stack[-2]-=$stat::stack[-1]; $stat::stack.pop(); print(\"-|\"); \n",
      "      } # Sub\n",
      "    | 'pow(' INT {a=int($INT.text)} ',' INT {b=int($INT.text)} ')'\n",
      "      {\n",
      "$stat::stack.append(math.pow(a,b)); print(\"pow\"); \n",
      "      } # Pow\n",
      "    | INT \n",
      "      {\n",
      "self.res+=$text; \n",
      "$stat::stack.append(int($text)); \n",
      "print(\"->\", $stat::stack)\n",
      "      } # Int\n",
      "    | ID # Id\n",
      "    | '(' e ')' # Braced\n",
      "    ;\n",
      "\n",
      "// Lexer rules after.\n",
      "INT: [0-9]+;\n",
      "ID: [a-zA-Z][a-zA-Z0-9]*;\n",
      "WS : [ \\r\\t\\n]+ ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat antlr_grammars/T3_incorrect.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66262805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd antlr_grammars && java -Xmx500M -cp \"/usr/local/lib/antlr-4.10.1-complete.jar:$CLASSPATH\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T2.g4\n",
    "!cd antlr_grammars && \\\n",
    "java -Xmx500M -cp \"/usr/local/lib/antlr-4.13.1-complete.jar\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T3_incorrect.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c0f50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'antlr_grammars.outputs.T3_incorrectLexer' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T3_incorrectLexer']\n",
    "if 'antlr_grammars.outputs.T3_incorrectParser' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T3_incorrectParser']\n",
    "from antlr_grammars.outputs.T3_incorrectLexer import T3_incorrectLexer\n",
    "from antlr_grammars.outputs.T3_incorrectParser import T3_incorrectParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cbab843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [16]\n",
      "-> [16, 2]\n",
      "processed [16, 2]\n",
      "/\n",
      "-> [8.0, 2]\n",
      "processed [8.0, 2]\n",
      "/\n",
      "pow\n",
      "-> [4.0, 81.0, 2]\n",
      "-> [4.0, 81.0, 2, 3]\n",
      "processed [4.0, 81.0, 2, 3]\n",
      "*\n",
      "processed [4.0, 81.0, 6]\n",
      "-|\n",
      "processed [4.0, 75.0]\n",
      "processed [4.0, 75.0]\n",
      "-|\n",
      "-> [-71.0, 5]\n",
      "-> [-71.0, 5, 6]\n",
      "processed [-71.0, 5, 6]\n",
      "*\n",
      "processed [-71.0, 30]\n",
      "-|\n",
      "processed [-101.0]\n",
      "calculated: [-101.0]\n"
     ]
    }
   ],
   "source": [
    "infile = InputStream(' return 16/2/2-(pow(3,4)-2*3)-5*6;')\n",
    "infile.consume()\n",
    "lexer3_i = T3_incorrectLexer(infile)\n",
    "stream = CommonTokenStream(lexer3_i)\n",
    "parser3_i = T3_incorrectParser(stream)\n",
    "tree = parser3_i.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c14ce7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener3(TListener):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.shift = ''\n",
    "        self.shiftSize = 3\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Add.\n",
    "    def enterAdd(self, ctx:TParser.AddContext):\n",
    "        print(self.shift + '+')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Add.\n",
    "    def exitAdd(self, ctx:TParser.AddContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Add.\n",
    "    def enterSub(self, ctx:TParser.AddContext):\n",
    "        print(self.shift + '-')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Add.\n",
    "    def exitSub(self, ctx:TParser.AddContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Mult.\n",
    "    def enterMult(self, ctx:TParser.MultContext):\n",
    "        print(self.shift + '*')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Mult.\n",
    "    def exitMult(self, ctx:TParser.MultContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Add.\n",
    "    def enterDiv(self, ctx:TParser.AddContext):\n",
    "        print(self.shift + '/')\n",
    "        self.shift += ' ' * self.shiftSize\n",
    "\n",
    "    # Exit a parse tree produced by TParser#Add.\n",
    "    def exitDiv(self, ctx:TParser.AddContext):\n",
    "        self.shift = self.shift[:-self.shiftSize]\n",
    "        \n",
    "    # Enter a parse tree produced by TParser#Id.\n",
    "    def enterId(self, ctx:TParser.IdContext):\n",
    "        print(self.shift + ctx.getText())\n",
    "\n",
    "    # Enter a parse tree produced by TParser#Int.\n",
    "    def enterInt(self, ctx:TParser.IntContext):\n",
    "        print(self.shift+ctx.getText())\n",
    "\n",
    "    def enterPow(self, ctx:TParser.IdContext):\n",
    "        print(self.shift + ctx.getText())\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "532e7506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "   -\n",
      "      /\n",
      "         /\n",
      "            16\n",
      "            2\n",
      "         2\n",
      "      -\n",
      "         pow(3,4)\n",
      "         *\n",
      "            2\n",
      "            3\n",
      "   *\n",
      "      5\n",
      "      6\n"
     ]
    }
   ],
   "source": [
    "printer = MyListener3()\n",
    "walker = ParseTreeWalker()\n",
    "walker.walk(printer, tree)\n",
    "# 16/2/2-(pow(3,4)-2*3)+5*6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9149f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c9b3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e6fb793-a93a-4ea6-9e7a-0b71cc6dc468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar T3_correct;\n",
      "\n",
      "@header {\n",
      "import math\n",
      "\n",
      "def make_op(stack, op):\n",
      "    if op == '*': \n",
      "        stack[-2] *= stack[-1] \n",
      "    elif op == '/':\n",
      "        stack[-2] /= stack[-1]\n",
      "    elif op == '+':\n",
      "        stack[-2] += stack[-1]\n",
      "    elif op == '-':\n",
      "        stack[-2] -= stack[-1]\n",
      "\n",
      "    stack.pop()\n",
      "    print(op)\n",
      "}\n",
      " \n",
      "@members {\n",
      "res = \"\"\n",
      "}\n",
      "\n",
      "// Rule stat.\n",
      "stat locals [stack=[]]    :\n",
      "          'return ' e ';' \n",
      "          {print(\"calculated:\", $stack)} # Return\n",
      " \t| 'break' ';' # Break\n",
      " \t;\n",
      "\n",
      "// Rule e.\n",
      "e   \n",
      "@after{print(\"processed\", $stat::stack);}\n",
      "    : e OP_MUL e \n",
      "      {make_op($stat::stack, $OP_MUL.text)\n",
      "      } # Mult\n",
      "    | e OP_ADD e \n",
      "      {make_op($stat::stack, $OP_ADD.text)\n",
      "      } # Add\n",
      "    | 'pow(' INT {a=int($INT.text)} ',' INT {b=int($INT.text)} ')'\n",
      "      {\n",
      "$stat::stack.append(math.pow(a,b)); print(\"pow\"); \n",
      "      } # Pow\n",
      "    | INT \n",
      "      {\n",
      "self.res+=$text; \n",
      "$stat::stack.append(int($text)); \n",
      "print(\"->\", $stat::stack)\n",
      "      } # Int\n",
      "    | ID # Id\n",
      "    | '(' e ')' # Braced\n",
      "    ;\n",
      "\n",
      "// Lexer rules after.\n",
      "INT: [0-9]+;\n",
      "ID: [a-zA-Z][a-zA-Z0-9]*;\n",
      "WS : [ \\r\\t\\n]+ ;\n",
      "OP_ADD: [+-];\n",
      "OP_MUL: [*/];\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat antlr_grammars/T3_correct.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c51e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd antlr_grammars && java -Xmx500M -cp \"/usr/local/lib/antlr-4.10.1-complete.jar:$CLASSPATH\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T2.g4\n",
    "!cd antlr_grammars && \\\n",
    "java -Xmx500M -cp \"/usr/local/lib/antlr-4.13.1-complete.jar\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T3_correct.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04c3f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'antlr_grammars.outputs.T3_correctLexer' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T3_correctLexer']\n",
    "if 'antlr_grammars.outputs.T3_correctParser' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T3_correctParser']\n",
    "from antlr_grammars.outputs.T3_correctLexer import T3_correctLexer\n",
    "from antlr_grammars.outputs.T3_correctParser import T3_correctParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f5b7fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [16]\n",
      "-> [16, 2]\n",
      "processed [16, 2]\n",
      "/\n",
      "-> [8.0, 2]\n",
      "processed [8.0, 2]\n",
      "/\n",
      "pow\n",
      "-> [4.0, 81.0, 2]\n",
      "-> [4.0, 81.0, 2, 3]\n",
      "processed [4.0, 81.0, 2, 3]\n",
      "*\n",
      "processed [4.0, 81.0, 6]\n",
      "-\n",
      "processed [4.0, 75.0]\n",
      "processed [4.0, 75.0]\n",
      "-\n",
      "-> [-71.0, 5]\n",
      "-> [-71.0, 5, 6]\n",
      "processed [-71.0, 5, 6]\n",
      "*\n",
      "processed [-71.0, 30]\n",
      "-\n",
      "processed [-101.0]\n",
      "calculated: [-101.0]\n"
     ]
    }
   ],
   "source": [
    "infile = InputStream(' return 16/2/2-(pow(3,4)-2*3)-5*6;')\n",
    "infile.consume()\n",
    "lexer3_c = T3_correctLexer(infile)\n",
    "stream = CommonTokenStream(lexer3_c)\n",
    "parser3_c = T3_correctParser(stream)\n",
    "tree = parser3_c.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ac80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae01fd3a-e9a4-4cf2-883e-c54ebd9a8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grammar T4;\n",
      "\n",
      "@header {\n",
      "import math\n",
      "\n",
      "def make_op(stack, op):\n",
      "    if op == '*': \n",
      "        stack[-2] *= stack[-1] \n",
      "    elif op == '/':\n",
      "        stack[-2] /= stack[-1]\n",
      "    elif op == '+':\n",
      "        stack[-2] += stack[-1]\n",
      "    elif op == '-':\n",
      "        stack[-2] -= stack[-1]\n",
      "\n",
      "    stack.pop()\n",
      "    print(op)\n",
      "}\n",
      " \n",
      "@members {\n",
      "values = {}\n",
      "}\n",
      "\n",
      "// Rule start.\n",
      "start:\n",
      "      (decl | a_expr)+\n",
      ";\n",
      "\n",
      "// Rule decl.\n",
      "decl:\n",
      "      'int' ID {self.values[$ID.text]=0} (',' ID {self.values[$ID.text]=0} )* ';' WS*\n",
      "{print('delcared', $text)\n",
      "}   \n",
      ";\n",
      "\n",
      "// Rule a_expr.\n",
      "a_expr locals [stack=[]]    :\n",
      "      ID {if $ID.text not in self.values.keys(): print(f\"wasn't declared:{$ID.text}\")} '=' e ';' WS*\n",
      "      {print(\"calculated:\", $stack);self.values[$ID.text]=$stack[-1];} # Return\n",
      "    | 'break' ';' # Break\n",
      ";\n",
      "\n",
      "// Rule e.\n",
      "e   \n",
      "@after{print(\"processed\", $a_expr::stack);}\n",
      "    : e OP_MUL e \n",
      "      {make_op($a_expr::stack, $OP_MUL.text)\n",
      "      } # Mult\n",
      "    | e OP_ADD e \n",
      "      {make_op($a_expr::stack, $OP_ADD.text)\n",
      "      } # Add\n",
      "    | 'pow(' INT {a=int($INT.text)} ',' INT {b=int($INT.text)} ')'\n",
      "      {\n",
      "$a_expr::stack.append(math.pow(a,b)); print(\"pow\"); \n",
      "      } # Pow\n",
      "    | INT \n",
      "      {\n",
      "$a_expr::stack.append(int($text)); \n",
      "print(\"->\", $a_expr::stack)\n",
      "      } # Int\n",
      "    | ID \n",
      "       {\n",
      "if $ID.text not in self.values.keys(): print(f\"wasn't declared:{$ID.text}\")\n",
      "else: $a_expr::stack.append(self.values[$text]); \n",
      "       } # Id\n",
      "    | '(' e ')' # Braced\n",
      "    ;\n",
      "\n",
      "// Lexer rules after.\n",
      "INT: [0-9]+;\n",
      "ID: [a-zA-Z][a-zA-Z0-9]*;\n",
      "WS : [ \\r\\t\\n]+ ;\n",
      "OP_ADD: [+-];\n",
      "OP_MUL: [*/];\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat antlr_grammars/T4.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f7bcd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd antlr_grammars && java -Xmx500M -cp \"/usr/local/lib/antlr-4.10.1-complete.jar:$CLASSPATH\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T2.g4\n",
    "!cd antlr_grammars && \\\n",
    "java -Xmx500M -cp \"/usr/local/lib/antlr-4.13.1-complete.jar\" org.antlr.v4.Tool -Dlanguage=Python3 -o outputs T4.g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2fd031b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'antlr_grammars.outputs.T4Lexer' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T4Lexer']\n",
    "if 'antlr_grammars.outputs.T4Parser' in sys.modules:  \n",
    "    del sys.modules['antlr_grammars.outputs.T4Parser']\n",
    "from antlr_grammars.outputs.T4Lexer import T4Lexer\n",
    "from antlr_grammars.outputs.T4Parser import T4Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1dec5c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delcared int id1,id2;\n",
      "-> [16]\n",
      "-> [16, 2]\n",
      "processed [16, 2]\n",
      "/\n",
      "-> [8.0, 2]\n",
      "processed [8.0, 2]\n",
      "/\n",
      "pow\n",
      "-> [4.0, 81.0, 2]\n",
      "-> [4.0, 81.0, 2, 3]\n",
      "processed [4.0, 81.0, 2, 3]\n",
      "*\n",
      "processed [4.0, 81.0, 6]\n",
      "-\n",
      "processed [4.0, 75.0]\n",
      "processed [4.0, 75.0]\n",
      "-\n",
      "-> [-71.0, 5]\n",
      "-> [-71.0, 5, 3]\n",
      "processed [-71.0, 5, 3]\n",
      "*\n",
      "processed [-71.0, 15]\n",
      "+\n",
      "processed [-56.0]\n",
      "calculated: [-56.0]\n",
      "-> [-56.0, 2]\n",
      "processed [-56.0, 2]\n",
      "*\n",
      "processed [-112.0]\n",
      "calculated: [-112.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "line 1:3 extraneous input ' ' expecting ID\n"
     ]
    }
   ],
   "source": [
    "infile = InputStream(' int id1,id2;id1=16/2/2-(pow(3,4)-2*3)+5*3;id2=id1*2;')\n",
    "infile.consume()\n",
    "lexer4 = T4Lexer(infile)\n",
    "stream = CommonTokenStream(lexer4)\n",
    "parser4 = T4Parser(stream)\n",
    "tree = parser4.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc169bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id1': -56.0, 'id2': -112.0}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aef58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
